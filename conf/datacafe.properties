#
#
# Copyright (c) 2016, Pradeeban Kathiravelu <pradeeban.kathiravelu@tecnico.ulisboa.pt>
#

# This is a sample Data Cafe properties file.
# Edit the values and/or add more properties accordingly based on your Data Cafe deployment configurations.

# Origin data server properties - host and port.
# Either a remote host such as "ec2-54-161-152-13.compute-1.amazonaws.com" or "localhost".
dataServerHost = localhost
dataServerPort = 27017
# Indicates whether the integrated data source is remote.
isRemote = false



# Hadoop properties
hadoopConf = /home/pradeeban/programs/hadoop-2.7.2/etc/hadoop
hdfsPath = /user/hdfs/
remoteTargetDir = ../hadoop/datacafe/

# SFTP remote configurations. Only if isRemote.
sftpPort = 22
sftpUser = ec2-user


# Client origin directory properties
# Can be a full path such as /home/hadoop/datacafe/ or a relative path.
clientOriginDir = ./

# optional. If left unspecified, clientOriginDir + "conf/" will be used.
clientCSVDir = ./conf/


# Hive properties. These properties are optional, as is Hive deployment.

# Either a remote host such as "ec2-54-158-108-220.compute-1.amazonaws.com" or "localhost".
hiveServer = localhost
hivePort = 10000
hiveUserName = hadoop
# If no password given, an empty string will be used.
#hivePassword =

hiveDriver = org.apache.hive.jdbc.HiveDriver

# Can be a full path such as /home/hadoop/datacafe/ or a relative path.
hiveCSVDir = datacafe/



# Information on the written data file.
# Include the dot as well.
fileExtension = .csv
delimiter = ,



privateKey = pradeeban.pem



inputBulkDir=.